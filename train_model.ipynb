{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, BatchNormalization, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('Datasets/X-c23-balanced.npy')\n",
    "y = np.load('Datasets/y-c23-balanced.npy')\n",
    "x_test = x[0:2000]\n",
    "y_test = y[0:2000]\n",
    "x_train = x[2001:]\n",
    "y_train = y[2001:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(8, kernel_size=3, activation='relu', input_shape=(100, 100, 3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(16, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(32, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(32, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13687 samples, validate on 2000 samples\n",
      "Epoch 1/500\n",
      "13687/13687 [==============================] - 4s 276us/step - loss: 0.3863 - accuracy: 0.8243 - val_loss: 0.6212 - val_accuracy: 0.6695\n",
      "Epoch 2/500\n",
      "13687/13687 [==============================] - 4s 279us/step - loss: 0.3612 - accuracy: 0.8358 - val_loss: 0.3655 - val_accuracy: 0.8250\n",
      "Epoch 3/500\n",
      "13687/13687 [==============================] - 4s 292us/step - loss: 0.3489 - accuracy: 0.8395 - val_loss: 0.8140 - val_accuracy: 0.5710\n",
      "Epoch 4/500\n",
      "13687/13687 [==============================] - 4s 288us/step - loss: 0.3250 - accuracy: 0.8537 - val_loss: 0.5304 - val_accuracy: 0.7360\n",
      "Epoch 5/500\n",
      "13687/13687 [==============================] - 4s 298us/step - loss: 0.3120 - accuracy: 0.8645 - val_loss: 0.4225 - val_accuracy: 0.7905\n",
      "Epoch 6/500\n",
      "13687/13687 [==============================] - 4s 301us/step - loss: 0.2921 - accuracy: 0.8702 - val_loss: 0.5431 - val_accuracy: 0.7345\n",
      "Epoch 7/500\n",
      "13687/13687 [==============================] - 4s 309us/step - loss: 0.2810 - accuracy: 0.8768 - val_loss: 0.7034 - val_accuracy: 0.6415\n",
      "Epoch 8/500\n",
      "13687/13687 [==============================] - 4s 291us/step - loss: 0.2702 - accuracy: 0.8834 - val_loss: 0.4952 - val_accuracy: 0.7580\n",
      "Epoch 9/500\n",
      "13687/13687 [==============================] - 4s 296us/step - loss: 0.2630 - accuracy: 0.8856 - val_loss: 0.2992 - val_accuracy: 0.8705\n",
      "Epoch 10/500\n",
      "13687/13687 [==============================] - 4s 295us/step - loss: 0.2470 - accuracy: 0.8957 - val_loss: 0.3497 - val_accuracy: 0.8275\n",
      "Epoch 11/500\n",
      "13687/13687 [==============================] - 4s 302us/step - loss: 0.2420 - accuracy: 0.8959 - val_loss: 0.3379 - val_accuracy: 0.8535\n",
      "Epoch 12/500\n",
      "13687/13687 [==============================] - 4s 296us/step - loss: 0.2304 - accuracy: 0.9009 - val_loss: 0.3050 - val_accuracy: 0.8600\n",
      "Epoch 13/500\n",
      "13687/13687 [==============================] - 4s 284us/step - loss: 0.2213 - accuracy: 0.9052 - val_loss: 0.3641 - val_accuracy: 0.8345\n",
      "Epoch 14/500\n",
      "13687/13687 [==============================] - 4s 283us/step - loss: 0.2195 - accuracy: 0.9071 - val_loss: 0.6168 - val_accuracy: 0.6950\n",
      "Epoch 15/500\n",
      "13687/13687 [==============================] - 4s 308us/step - loss: 0.2108 - accuracy: 0.9133 - val_loss: 0.1698 - val_accuracy: 0.9350\n",
      "Epoch 16/500\n",
      "13687/13687 [==============================] - 4s 308us/step - loss: 0.1997 - accuracy: 0.9152 - val_loss: 0.4299 - val_accuracy: 0.7975\n",
      "Epoch 17/500\n",
      "13687/13687 [==============================] - 4s 296us/step - loss: 0.1946 - accuracy: 0.9180 - val_loss: 0.3599 - val_accuracy: 0.8310\n",
      "Epoch 18/500\n",
      "13687/13687 [==============================] - 4s 284us/step - loss: 0.1842 - accuracy: 0.9242 - val_loss: 0.3891 - val_accuracy: 0.8065\n",
      "Epoch 19/500\n",
      "13687/13687 [==============================] - 4s 291us/step - loss: 0.1776 - accuracy: 0.9244 - val_loss: 0.3678 - val_accuracy: 0.8285\n",
      "Epoch 20/500\n",
      "13687/13687 [==============================] - 4s 283us/step - loss: 0.1718 - accuracy: 0.9283 - val_loss: 0.2690 - val_accuracy: 0.8760\n",
      "Epoch 21/500\n",
      "13687/13687 [==============================] - 4s 286us/step - loss: 0.1678 - accuracy: 0.9321 - val_loss: 0.2713 - val_accuracy: 0.8810\n",
      "Epoch 22/500\n",
      "13687/13687 [==============================] - 4s 287us/step - loss: 0.1694 - accuracy: 0.9286 - val_loss: 0.3191 - val_accuracy: 0.8405\n",
      "Epoch 23/500\n",
      "13687/13687 [==============================] - 4s 297us/step - loss: 0.1582 - accuracy: 0.9364 - val_loss: 0.4392 - val_accuracy: 0.7825\n",
      "Epoch 24/500\n",
      "13687/13687 [==============================] - 4s 305us/step - loss: 0.1508 - accuracy: 0.9364 - val_loss: 0.2568 - val_accuracy: 0.8845\n",
      "Epoch 25/500\n",
      "13687/13687 [==============================] - 4s 281us/step - loss: 0.1472 - accuracy: 0.9394 - val_loss: 0.1956 - val_accuracy: 0.9150\n",
      "Epoch 26/500\n",
      "13687/13687 [==============================] - 4s 306us/step - loss: 0.1441 - accuracy: 0.9419 - val_loss: 0.1785 - val_accuracy: 0.9300\n",
      "Epoch 27/500\n",
      "13687/13687 [==============================] - 4s 284us/step - loss: 0.1381 - accuracy: 0.9425 - val_loss: 0.1163 - val_accuracy: 0.9560\n",
      "Epoch 28/500\n",
      "13687/13687 [==============================] - 4s 297us/step - loss: 0.1315 - accuracy: 0.9463 - val_loss: 0.2758 - val_accuracy: 0.8745\n",
      "Epoch 29/500\n",
      "13687/13687 [==============================] - 4s 286us/step - loss: 0.1289 - accuracy: 0.9477 - val_loss: 0.2451 - val_accuracy: 0.8860\n",
      "Epoch 30/500\n",
      "13687/13687 [==============================] - 4s 288us/step - loss: 0.1230 - accuracy: 0.9494 - val_loss: 0.1651 - val_accuracy: 0.9310\n",
      "Epoch 31/500\n",
      "13687/13687 [==============================] - 4s 284us/step - loss: 0.1237 - accuracy: 0.9465 - val_loss: 0.0785 - val_accuracy: 0.9735\n",
      "Epoch 32/500\n",
      "13687/13687 [==============================] - 4s 285us/step - loss: 0.1207 - accuracy: 0.9505 - val_loss: 0.2402 - val_accuracy: 0.8915\n",
      "Epoch 33/500\n",
      "13687/13687 [==============================] - 4s 291us/step - loss: 0.1062 - accuracy: 0.9577 - val_loss: 0.1683 - val_accuracy: 0.9255\n",
      "Epoch 34/500\n",
      "13687/13687 [==============================] - 4s 286us/step - loss: 0.1073 - accuracy: 0.9559 - val_loss: 0.1131 - val_accuracy: 0.9560\n",
      "Epoch 35/500\n",
      "13687/13687 [==============================] - 4s 299us/step - loss: 0.1017 - accuracy: 0.9596 - val_loss: 0.1014 - val_accuracy: 0.9635\n",
      "Epoch 36/500\n",
      "13687/13687 [==============================] - 4s 304us/step - loss: 0.1025 - accuracy: 0.9570 - val_loss: 0.0969 - val_accuracy: 0.9630\n",
      "Epoch 37/500\n",
      "13687/13687 [==============================] - 4s 309us/step - loss: 0.1002 - accuracy: 0.9596 - val_loss: 0.1763 - val_accuracy: 0.9240\n",
      "Epoch 38/500\n",
      "13687/13687 [==============================] - 4s 286us/step - loss: 0.0928 - accuracy: 0.9629 - val_loss: 0.1350 - val_accuracy: 0.9445\n",
      "Epoch 39/500\n",
      "13687/13687 [==============================] - 4s 282us/step - loss: 0.0880 - accuracy: 0.9651 - val_loss: 0.1289 - val_accuracy: 0.9500\n",
      "Epoch 40/500\n",
      "13687/13687 [==============================] - 4s 287us/step - loss: 0.0877 - accuracy: 0.9652 - val_loss: 0.1884 - val_accuracy: 0.9160\n",
      "Epoch 41/500\n",
      "13687/13687 [==============================] - 4s 278us/step - loss: 0.0815 - accuracy: 0.9689 - val_loss: 0.1529 - val_accuracy: 0.9410\n",
      "Epoch 42/500\n",
      "13687/13687 [==============================] - 4s 287us/step - loss: 0.0803 - accuracy: 0.9670 - val_loss: 0.0898 - val_accuracy: 0.9660\n",
      "Epoch 43/500\n",
      "13687/13687 [==============================] - 4s 283us/step - loss: 0.0813 - accuracy: 0.9688 - val_loss: 0.1604 - val_accuracy: 0.9345\n",
      "Epoch 44/500\n",
      "13687/13687 [==============================] - 4s 280us/step - loss: 0.0805 - accuracy: 0.9680 - val_loss: 0.0606 - val_accuracy: 0.9790\n",
      "Epoch 45/500\n",
      "13687/13687 [==============================] - 4s 287us/step - loss: 0.0690 - accuracy: 0.9737 - val_loss: 0.1023 - val_accuracy: 0.9630\n",
      "Epoch 46/500\n",
      "13687/13687 [==============================] - 4s 280us/step - loss: 0.0697 - accuracy: 0.9729 - val_loss: 0.0888 - val_accuracy: 0.9700\n",
      "Epoch 47/500\n",
      "13687/13687 [==============================] - 4s 277us/step - loss: 0.0678 - accuracy: 0.9732 - val_loss: 0.0889 - val_accuracy: 0.9655\n",
      "Epoch 48/500\n",
      "13687/13687 [==============================] - 4s 276us/step - loss: 0.0617 - accuracy: 0.9759 - val_loss: 0.0980 - val_accuracy: 0.9625\n",
      "Epoch 49/500\n",
      "13687/13687 [==============================] - 4s 295us/step - loss: 0.0616 - accuracy: 0.9768 - val_loss: 0.0674 - val_accuracy: 0.9780\n",
      "Epoch 50/500\n",
      "13687/13687 [==============================] - 4s 283us/step - loss: 0.0658 - accuracy: 0.9757 - val_loss: 0.1165 - val_accuracy: 0.9500\n",
      "Epoch 51/500\n",
      "13687/13687 [==============================] - 4s 285us/step - loss: 0.0552 - accuracy: 0.9801 - val_loss: 0.0888 - val_accuracy: 0.9680\n",
      "Epoch 52/500\n",
      "13687/13687 [==============================] - 4s 293us/step - loss: 0.0678 - accuracy: 0.9735 - val_loss: 0.0469 - val_accuracy: 0.9855\n",
      "Epoch 53/500\n",
      "13687/13687 [==============================] - 4s 284us/step - loss: 0.0482 - accuracy: 0.9825 - val_loss: 0.1661 - val_accuracy: 0.9345\n",
      "Epoch 54/500\n",
      "13687/13687 [==============================] - 4s 290us/step - loss: 0.0470 - accuracy: 0.9847 - val_loss: 0.0492 - val_accuracy: 0.9845\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13687/13687 [==============================] - 4s 287us/step - loss: 0.0546 - accuracy: 0.9795 - val_loss: 0.0503 - val_accuracy: 0.9790\n",
      "Epoch 56/500\n",
      "13687/13687 [==============================] - 4s 288us/step - loss: 0.0471 - accuracy: 0.9830 - val_loss: 0.0663 - val_accuracy: 0.9800\n",
      "Epoch 57/500\n",
      "13687/13687 [==============================] - 4s 285us/step - loss: 0.0553 - accuracy: 0.9797 - val_loss: 0.1462 - val_accuracy: 0.9460\n",
      "Epoch 58/500\n",
      "13687/13687 [==============================] - 4s 285us/step - loss: 0.0390 - accuracy: 0.9866 - val_loss: 0.1914 - val_accuracy: 0.9150\n",
      "Epoch 59/500\n",
      "13687/13687 [==============================] - 4s 289us/step - loss: 0.0520 - accuracy: 0.9810 - val_loss: 0.0549 - val_accuracy: 0.9805\n",
      "Epoch 60/500\n",
      "13687/13687 [==============================] - 4s 282us/step - loss: 0.0460 - accuracy: 0.9830 - val_loss: 0.0395 - val_accuracy: 0.9890\n",
      "Epoch 61/500\n",
      "13687/13687 [==============================] - 4s 286us/step - loss: 0.0405 - accuracy: 0.9857 - val_loss: 0.0208 - val_accuracy: 0.9940\n",
      "Epoch 62/500\n",
      "13687/13687 [==============================] - 4s 294us/step - loss: 0.0464 - accuracy: 0.9840 - val_loss: 0.0491 - val_accuracy: 0.9845\n",
      "Epoch 63/500\n",
      "13687/13687 [==============================] - 4s 284us/step - loss: 0.0388 - accuracy: 0.9872 - val_loss: 0.1190 - val_accuracy: 0.9490\n",
      "Epoch 64/500\n",
      "13687/13687 [==============================] - 4s 288us/step - loss: 0.0430 - accuracy: 0.9845 - val_loss: 0.0676 - val_accuracy: 0.9755\n",
      "Epoch 65/500\n",
      "13687/13687 [==============================] - 4s 295us/step - loss: 0.0325 - accuracy: 0.9897 - val_loss: 0.1227 - val_accuracy: 0.9535\n",
      "Epoch 66/500\n",
      "13687/13687 [==============================] - 4s 294us/step - loss: 0.0306 - accuracy: 0.9895 - val_loss: 0.1628 - val_accuracy: 0.9400\n",
      "Epoch 67/500\n",
      "13687/13687 [==============================] - 4s 286us/step - loss: 0.0372 - accuracy: 0.9874 - val_loss: 0.0158 - val_accuracy: 0.9960\n",
      "Epoch 68/500\n",
      "13687/13687 [==============================] - 4s 286us/step - loss: 0.0361 - accuracy: 0.9866 - val_loss: 0.0274 - val_accuracy: 0.9920\n",
      "Epoch 69/500\n",
      "13687/13687 [==============================] - 4s 287us/step - loss: 0.0440 - accuracy: 0.9825 - val_loss: 0.1171 - val_accuracy: 0.9515\n",
      "Epoch 70/500\n",
      "13687/13687 [==============================] - 4s 289us/step - loss: 0.0274 - accuracy: 0.9907 - val_loss: 0.0158 - val_accuracy: 0.9965\n",
      "Epoch 71/500\n",
      "13687/13687 [==============================] - 4s 282us/step - loss: 0.0401 - accuracy: 0.9853 - val_loss: 0.1100 - val_accuracy: 0.9570\n",
      "Epoch 72/500\n",
      "13687/13687 [==============================] - 4s 283us/step - loss: 0.0270 - accuracy: 0.9911 - val_loss: 0.0213 - val_accuracy: 0.9950\n",
      "Epoch 73/500\n",
      "13687/13687 [==============================] - 4s 282us/step - loss: 0.0299 - accuracy: 0.9897 - val_loss: 0.0242 - val_accuracy: 0.9935\n",
      "Epoch 74/500\n",
      "13687/13687 [==============================] - 4s 287us/step - loss: 0.0326 - accuracy: 0.9886 - val_loss: 0.0303 - val_accuracy: 0.9910\n",
      "Epoch 75/500\n",
      "13687/13687 [==============================] - 4s 290us/step - loss: 0.0354 - accuracy: 0.9871 - val_loss: 0.0290 - val_accuracy: 0.9915\n",
      "Epoch 76/500\n",
      "13687/13687 [==============================] - 4s 291us/step - loss: 0.0239 - accuracy: 0.9925 - val_loss: 0.0154 - val_accuracy: 0.9955\n",
      "Epoch 77/500\n",
      "13687/13687 [==============================] - 4s 288us/step - loss: 0.0319 - accuracy: 0.9893 - val_loss: 0.0222 - val_accuracy: 0.9925\n",
      "Epoch 78/500\n",
      "13687/13687 [==============================] - 4s 287us/step - loss: 0.0259 - accuracy: 0.9908 - val_loss: 0.0250 - val_accuracy: 0.9910\n",
      "Epoch 79/500\n",
      "13687/13687 [==============================] - 4s 289us/step - loss: 0.0191 - accuracy: 0.9949 - val_loss: 0.0291 - val_accuracy: 0.9905\n",
      "Epoch 80/500\n",
      "13687/13687 [==============================] - 4s 285us/step - loss: 0.0398 - accuracy: 0.9865 - val_loss: 0.0086 - val_accuracy: 0.9980\n",
      "Epoch 81/500\n",
      "13687/13687 [==============================] - 4s 293us/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 0.0814 - val_accuracy: 0.9670\n",
      "Epoch 82/500\n",
      "13687/13687 [==============================] - 4s 291us/step - loss: 0.0382 - accuracy: 0.9848 - val_loss: 0.0293 - val_accuracy: 0.9900\n",
      "Epoch 83/500\n",
      " 9472/13687 [===================>..........] - ETA: 1s - loss: 0.0244 - accuracy: 0.9928"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-bfae8f16e496>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3292\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x, y, validation_data=(x_test, y_test), epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile a model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-113a54cbdef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1347\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1350\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m                 raise RuntimeError('You must compile a model before '\n\u001b[0m\u001b[1;32m    509\u001b[0m                                    \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m                                    'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile a model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.json', 'w') as json_file:\n",
    "    json_file.write(model.to_json())\n",
    "    model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.json', 'r') as json_file:\n",
    "    model = keras.models.model_from_json(json_file.read())\n",
    "    model.load_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 154us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.003956730615435901, 0.9990000128746033]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
